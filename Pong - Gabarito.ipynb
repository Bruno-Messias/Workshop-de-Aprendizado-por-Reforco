{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üïπ Pong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALFA = 0.05          # learning rate\n",
    "EPSILON_MIN = 0.01   # valor m√≠nimo de epsilon\n",
    "EPSILON = 0.7        # valor inicial do epsilon\n",
    "DECAIMENTO = 0.98    # fator deca√≠mento do epsilon (por epis√≥dio)\n",
    "GAMA = 0.9           # fator de desconto\n",
    "N_EPISODIOS = 250    # n√∫mero de epis√≥dios\n",
    "\n",
    "# dicion√°rio dos valores de Q\n",
    "# chaves: estados; valores: valor atribuido a cada a√ß√£o\n",
    "Q = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"pong:turing-easy-v0\")\n",
    "\n",
    "# n√∫mero total de a√ß√µes: 3\n",
    "# 0 = parado; 1 = baixo; 2 = cima\n",
    "n_acoes = env.action_space.n\n",
    "\n",
    "print('N√∫mero de a√ß√µes:', n_acoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretiza_estado(estado):\n",
    "    return tuple(round(x/10) for x in estado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salva_tabela(Q, nome = 'model.pickle'):\n",
    "    with open(nome, 'wb') as pickle_out:\n",
    "        pickle.dump(Q, pickle_out)\n",
    "\n",
    "def carrega_tabela(nome = 'model.pickle'):\n",
    "    with open(nome, 'rb') as pickle_out:\n",
    "        return pickle.load(pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escolhe_acao(env, Q, estado, epsilon):\n",
    "    if estado not in Q.keys(): Q[estado] = [0] * n_acoes\n",
    "\n",
    "    if np.random.random() < epsilon:\n",
    "        acao = env.action_space.sample()\n",
    "    else:\n",
    "        acao = np.argmax(Q[estado])\n",
    "    return acao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atualiza_q(Q, estado, acao, recompensa, prox_estado):\n",
    "    # para cada estado ainda n√£o descoberto, iniciamos seu valor como nulo\n",
    "    if estado not in Q.keys(): Q[estado] = [0] * n_acoes\n",
    "    if prox_estado not in Q.keys(): Q[prox_estado] = [0] * n_acoes\n",
    "\n",
    "    # equa√ß√£o de Bellman\n",
    "    Q[estado][acao] = Q[estado][acao] + ALFA*(recompensa + GAMA*np.max(Q[prox_estado]) - Q[estado][acao])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roda_partida(env, Q, renderiza=True):\n",
    "    estado = env.reset()\n",
    "    estado = discretiza_estado(estado)\n",
    "    \n",
    "    done = False\n",
    "    retorno = 0\n",
    "    \n",
    "    while not done:\n",
    "        # politica\n",
    "        acao = escolhe_acao(env, Q, estado, epsilon=0)\n",
    "\n",
    "        # A a√ß√£o √© tomada e os valores novos s√£o coletados\n",
    "        # O novo estado √© salvo numa nova variavel\n",
    "        prox_estado, recompensa, done, info = env.step(acao)\n",
    "        prox_estado = discretiza_estado(prox_estado)\n",
    "\n",
    "        if renderiza:\n",
    "            env.render()\n",
    "\n",
    "        retorno += recompensa\n",
    "        estado = prox_estado\n",
    "\n",
    "    print(f'retorno {retorno:.1f},  '\n",
    "          f'placar {env.score[0]}x{env.score[1]}')\n",
    "    \n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roda_partida(env, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treina(env, Q):\n",
    "    retornos = []      # retorno de cada epis√≥dio\n",
    "    epsilon = EPSILON\n",
    "\n",
    "    for episodio in range(1, N_EPISODIOS+1):\n",
    "        estado = env.reset()\n",
    "        estado = discretiza_estado(estado)\n",
    "        \n",
    "        done = False\n",
    "        retorno = 0\n",
    "        \n",
    "        while not done:\n",
    "            # politica\n",
    "            acao = escolhe_acao(env, Q, estado, epsilon)\n",
    "\n",
    "            # A a√ß√£o √© tomada e os valores novos s√£o coletados\n",
    "            # O novo estado √© salvo numa nova variavel\n",
    "            prox_estado, recompensa, done, info = env.step(acao)\n",
    "            prox_estado = discretiza_estado(prox_estado)\n",
    "\n",
    "            atualiza_q(Q, estado, acao, recompensa, prox_estado)\n",
    "\n",
    "            retorno += recompensa\n",
    "            estado = prox_estado\n",
    "\n",
    "        epsilon = max(DECAIMENTO*epsilon, EPSILON_MIN)\n",
    "        retornos.append(retorno)\n",
    "\n",
    "        if episodio % 10 == 0:\n",
    "            salva_tabela(Q)\n",
    "\n",
    "        print(f'epis√≥dio {episodio},  '\n",
    "              f'retorno {retorno:7.1f},  '\n",
    "              f'retorno m√©dio (√∫ltimos 10 epis√≥dios) {np.mean(retornos[-10:]):7.1f},  '\n",
    "              f'placar {env.score[0]}x{env.score[1]},  '\n",
    "              f'epsilon: {epsilon:.3f}')\n",
    "        \n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "treina(env, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roda_partida(env, Q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}